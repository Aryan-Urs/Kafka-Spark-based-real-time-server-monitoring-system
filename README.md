# ğŸ§  Sparkâ€“Kafka Server Monitoring

This project implements a **Kafkaâ€“Spark batch processing system** to monitor server metrics in real time.  
It consumes **CPU, Memory, Network, and Disk** data from Kafka topics, aggregates them in **sliding windows**, and raises alerts when usage thresholds are exceeded.

---

## âš™ï¸ Project Structure
â”‚
â”œâ”€â”€ consumer1.py # Reads CPU + MEM data from Kafka and saves raw CSVs
â”œâ”€â”€ sparkjob1.py # Processes CPU + MEM CSVs â†’ team_87_CPU_MEM.csv
â”‚
â”œâ”€â”€ consumer2.py # Reads NET + DISK data from Kafka and saves raw CSVs
â”œâ”€â”€ sparkjob2.py # Processes NET + DISK CSVs â†’ team_87_NET_DISK.csv
â”‚
â”œâ”€â”€ thresholds.txt # Threshold values for alerts
â”œâ”€â”€ README.md # Project documentation (this file)
â””â”€â”€ *.csv # Generated output files



---

## ğŸ§© Data Flow Diagram

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kafka Topics  â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ Consumers   â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ Raw CSVs    â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ Spark Jobs   â”‚
â”‚ (cpu, mem,    â”‚       â”‚ (consumer1, â”‚       â”‚ (cpu_data,  â”‚       â”‚ (sparkjob1,  â”‚
â”‚ net, disk)    â”‚       â”‚ consumer2)  â”‚       â”‚ mem_data...)â”‚       â”‚ sparkjob2)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                           â–¼
                                                                   Processed CSV Reports
                                                                   (team_87_CPU_MEM.csv,
                                                                    team_87_NET_DISK.csv)
